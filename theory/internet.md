## The Erosion of Trust Online
The first internet communities of the 1980s, the homo erectus to our modern homo sapien internet communities, were small and isolated.

Before the internet became mainstream, it was shaped mostly by researchers (acadmic and military (nerds)) and hobbyists (also nerds). Those were the people willing to dedicate time to text-based communication instead of just calling people and those were the people who had the technical knowledge (and time) to overcome the non-user friendly setup for the hardware and software you needed.

The people on the network knew each other then. Unlike todays internet, online spam wasn't a global pandemic. The word "spam" comes from a Monty Python sketch in the 1970s 
>"Spam, Spam, Spam, Spamâ€¦ Lovely Spam! Wonderful Spam!"
that nerds in the 1980s would mimic on their discussion boards. It wouldn't be until 1998 that dictionaries would include it to mean
>"Irrelevant or inappropriate messages sent on the Internet to a large number of newsgroups or users."

What happened in those 20 years? In short, the internet became mainstream. In long, internent communities lost their power to self-regulate. The early internet had a kind of culture where people understood that individuals had the power to annoy the collective and that it was a bad thing to do that. If someone was spamming and ruining the discussion, everyone would hate on them until they stopped and were sure they wouldn't be tolerated around these parts. But once the internet was big enough, the sheer number of people in one place created an economic incentive that was too big for unorganized resistance.


## Bots

Cat is out of the bag. Starting open conversation spaces on the modern internet quickly get overcome by spams, scam, and bots. You can't trust people to regulate themselves in an open space because the sheer volume of nonsense is too big to be bullied away or blocked one by one. People running social media applications, like Elon Musk, either try to solve the problem (1) technologically or (2) monetarily. Both are top-down band-aid solutions that miss the fundamentals of how communication works.

The actual problem is:
1. There are geniuine people on the internet. Lots of them.
2. Genuine people want to talk to each other.
3. It is not that hard to trick genuine people into clicking on things that aren't good for them.
4. It is very very valuable to trick genuine people into clicking on things that aren't good for them.

You see the massive economic problem? Big groups of people are like giant money bags. You can send an evil link out there and even if most people won't bite on a spam link, someone will.

Left unchecked it's like a group of shrimp: no defences, just waiting to get eaten by the next big fish.

Technological solutions don't solve the problem because they can be overcome with other clever technology. You pay to build a wall, they pay to build a ladder. You need to win every battle, they only need to win one for a pay day.

Monetary solutions like requiring someone to pay $8 dollars to use the site have the exact same issue. If my pay day is bigger than the cost to join, then I'm already joining yesterday. If the cost to join is bigger than the potentital pay day, you're not going to have many users because nobody is paying thousands of dollars to join a damn website.


## Problems

Users become users and not participants in a shared space because the enforcements of the safety of their communities is abstracted away from them. You don't see the African, South American, and Souther Pacific Asian workers that have to look at all of the awful images that get posted on social media so they don't end up on your feed. You don't see, hear, or participate in the discussions that limit what counts as spam or what counts as dangerous. These questions are icky and gross so corporations "protect" you from them. They create their own rules based on what is most profitable, hire workers somewhere else in the world to enforce them, and then you just have to deal with it. Don't like it? Easy. Just get a few billion dollars of investment money, 100 lawyers, and then make your own.

## Solutions

I don't have billions of dollars and I don't plan to make something profitable so there will not be billions of dollars bestowed upon me. A real solution has to come from the bottom-up, slowly displacing what already exists rather than simply smashing it. Smashing it all is tempting because it creates a vaccum of possibility. However, those with the most resources will always default to being the most prepared for that exact scenario. Unless you have something ready to replace what already exists, and a plan to implement it, you are not prepared for the vaccum. How do we displace what exists?

Well we have to solve a problem and we have to solve it in a way that benefits us relative to them. You ever notice how every sign-in these days has like 4 different options? Sign-in with google, sign-in with facebook, sign-in with pizza hut rewards card.. If you are making a new site, it's probably a smart move to do something like that because (1) users don't have to remember another username/password and (2) you get to offload all the work of verification to someone else. You, the little app maker, don't have to be responsible for figuring out who to trust and who not to trust. You let google do it for you just like everyone else. 

The goal of YKM is to solve both of these problems by offloading the work of verification to people you already trust. At a surface level, it is a way for people to share passwords without creating an additional password. Further, it is a way for a group of people to reliably verify each other. The goal is to slowly create communities capable of self-regulating that simultaneously (1) defends community members from outside exploitation and (2) takes power away from corporations and states by putting self-identification away from central corporate/government databases and into the hands of people you trust in real life.